\section{Theoretical background}
 
In this research proposal we consider a variety of  problems regarding the computation of extremal distance parameters in graphs. Let $G =(V,E)$ be a graph. The All-Pair-Shortest-Path (APSP) problem is defined as follows: Compute the length of the shortest path between each pair of vertices $u,v \in V$ in $G$. The APSP problem is one of the most fundamental problems in Computer Science. Many graph parameters, such as the girth, the diameter, the radius and the eccentricity can be calculated using the solution of the APSP.

The fastest known algorithm for solving the APSP has a running time of  $\mathcal{\tilde{O}}(mn)$ \cite{T99} where $m=|E|$ and $n=|V|$ (faster algorithms are known for specific graph types).

Dor, Halperin and Zwick \cite{DHZ2000} presented an algorithm  that computes all pairs approximate distances in undirected, unweighted graphs with an additive error of $2$ in $\mathcal{\tilde{O}}(min\{n^{3/2}\sqrt{m},n^{7/3}\})$ time. They also presented a more general algorithm that has a running time of $\mathcal{\tilde{O}}(min\{n^{2-\frac{2}{k+2}}m^{\frac{2}{k+2}},n^{2+\frac{2}{3k-2}}\})$ and an additive error $k$  for every even $k>2$ .
As for lower bounds, Dor \etal showed that computing an additive one-sided error of at most $1$ for the APSP is as hard as Boolean Matrix Multiplication (BMM).


An important theoretical and practical question for each one of the graph parameters mentioned above, is whether it possible to compute the parameter without computing the APSP explicitly.
For example consider the girth problem witch is defined as finding the  minimum weight cycle in a graph. Vassilevska W. and Williams \citep{WW10} proved that in undirected graphs with integral weights from the rang $[-M,M]$ finding the girth is as hard as the APSP problem. 


As opposed to the minimum weight cycle problem, for the diameter, we do not know if solving the diameter is as hard as solving the APSP, or if a more efficient algorithm exists. Even for the more restricted problem of distinguishing between graphs having a diameter of $2$ or $3$, it is not known whether there exists a more efficient algorithm. 
%It is also not known whether distinguishing between a graph of diameter 
%2 an a graph of diameter of 3 is easier than computing the exact diameter problem.

In light of the above discussion, a natural research direction is to find an efficient algorithm for approximating the diameter.  It is well-known that a 2-approximation for the diameter is easy to achieve in $\mathcal{O}(m + n)$ time as follows: run a Breath-First-Search (BFS) from an arbitrary vertex and return the maximum distance found. (For directed graphs run a bfs from and to an arbitrary vertex, for weighted graph use Dijkstra's algorithm \cite{D59} instead). Thus, in sparse graphs computing a 2-approximation for the diameter is easier then APSP.

The first approximation algorithm for the diameter was presented by Aingworth, Chekuri, Indyk, and Motwani \cite{siam1999}. Their first result is a randomized algorithm for undirected and directed graphs, that distinguishes between graphs of diameter 2 and 4 in $\mathcal{O}(m \sqrt{n\log n})$ time.

Using the above result they also showed approximation algorithm with an almost $3/2$ approximation ratio. The algorithm gives an estimate $\hat{D}$ for the diameter $D$, such that $\floor{2/3}D \leq \hat{D} \leq D$, thus this result gives almost a 3/2-approximation. Aingworth \etal posted the following open problem: is it possible to distinguish between graphs of diameter 2 and 3 in less than $\mathcal{O}(mn)$ time.

Boitmanis \etal \cite{KK06} obtain an algorithm that computes an approximation for the diameter with an additive error of $\sqrt{n}$ in $\mathcal{O}(m\sqrt{n})$ time. Their algorithm is based on the algorithm of Aingworth \etal. Moreover, this is the first approximation algorithm for the diameter with an additive error. 

Roddity and Vassilevska W. developed  \cite{LV2013} a new algorithm for dense undirected unweighted graphs (a dense graph is a graph in which the number of edges is nearly $O(n^2)$), in which the algorithm gives an estimate $\hat{D}$ for the diameter $D$ such that $\floor{4/5}D \leq \hat{D} \leq D$ the algorithm they showed has $\mathcal{\tilde{O}}(m^{2/3}n^{4/3})$ running time. In addition, they also improved the algorithm of Aingworth \etal by presenting an approximation algorithm of nearly 3/2 in $\mathcal{\tilde{O}}(m\sqrt{n})$ time.

As for lower bounds, they also showed a reduction from the K-Dominating-Set problem to prove that under the Strong Exponential Time Hypothesis (SETH) no algorithm can distinguish between graphs with a diameter of 2 and  3 in less than $\mathcal{O}(n^{2-\epsilon})$ time. 

Inspired by Roditty and Vassilevska W. \cite{LV2013} result, Cairo, Grossi, and Rizzi \cite{CGR16} presented a reduction from the $SAT$ problem to prove that under SETH it is impossible to get $(3/2-\epsilon)$-approximation for the diameter in less than $\mathcal{O}(n^{2-\epsilon})$ time.

One recent result of Roditty, Schoenebeck, Endre, Chechik, H. Larkin and Vassilevska W.
\cite{SDLLGREV2000}, presented a two deterministic algorithms for the diameter with 2/3 approximation, one with $\mathcal{\tilde{O}}(m^{3/2})$ time and the other with $\mathcal{\tilde{O}}(mn^{2/3})$ time.
Those two algorithms are the first deterministic algorithms that run in subquadratic time and give $(2-\epsilon)$-approximation.


%In many algorithms, in order to improve running time, we use the %following tools:
%\begin{itemize}
%    \item \textbf{Approximation} we use approximation of the original problem with provable guarantees on the distance of the returned solution to the optimal one in order to get better run time.
%    \item  \textbf{Randomized} we use randomness as part of the algoritme. there two main Randomized technique "Monte Carlo algorithm" whose output may be incorrect with a certain probability, and "Las Vegas algorithm" whose run time may be bigger with a certain probability.
%\end{itemize}




Another fundamental graphs parameter is the Eccentricities, i.e. the largest distance from each vertex. 
Roditty and W. Vassilevska \cite{LV2013} presented an algorithm that when the diameter and the radius are $D,r$ respectively for every $u \in V$ estimate $\hat{e(u)}$ such that $max\{r,2/3ecc(u)\} \leq \hat{e(u)} \leq min\{D,3/2ecc(u)\}$ in $\mathcal{\tilde{O}}(m\sqrt{n})$ time.

Roditty, Schoenebeck, Endre, Chechik, H. Larkin and W. Vassilevska
show in \cite{SDLLGREV2000} that a variant of Roditty and Vassilevska W. algorithm \cite{LV2013} can give a better approximation with the same running time, they show approximation of $3/5e(u)\leq \hat{e(u)} \leq e(u)$.

Abboud, W. Vassilevska and R. Wang \cite{AVJ2016} used an Orthogonal Vectors Conjecture to prove that no algorithm can achieve better than a 5/3 approximation in $\mathcal{O}(n^{2-\epsilon})$ time, for the eccentricity problem.

A more recent result shown by Lincoln, W. Vassilevska and Williams \cite{AVR2018} proves that under the complexity of a weighted Clique, the eccentricity problem cannot be beaten by any polynomial runtime in the form of $\mathcal{O}(mn)$
for $m=O(n^{1+1/k})$ for integer k.


%Another closely problem is the Round-Trip-Time of the diameter and %the radius. Amir, Virginia and Joshua deifine in \cite{AVJ2016} the %RTT-Diameter as follow $max_{u,v}\{d(u,v)+d(u,v)\}$. They found new %reduction from the Orthogonal-Vector problem to the Rtt-Diameter %problem and the proof that no algorithme can approximate the %rtt-diameter problen better then 2/3 in %$\mathcal{O}(n^{2-\epsilon})$ time.
